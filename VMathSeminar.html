<!-- For Spring 2025 -->
<html>
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
    <script id="MathJax-script" async
            src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
    </script>
    <link rel="stylesheet" href="https://code.jquery.com/mobile/1.4.5/jquery.mobile-1.4.5.min.css">
    <script src="https://code.jquery.com/jquery-1.11.3.min.js"></script>
    <script src="https://code.jquery.com/mobile/1.4.5/jquery.mobile-1.4.5.min.js"></script>

    <style>
      table#t1 {
      border-collapse: collapse;
      width: 80%;
      }

      table#t1 tr:nth-child(even) {
      background-color: #e0e0d9;
      text-align: center;
      }
      table#t1 tr:nth-child(odd) {
      background-color:#fff;
      text-align: center;
      }
      table#t1 th	{
      background-color: #9d9e9b;
      color: white;
      text-align: center;
      }
      
      .serif {
	  font-family: "Times New Roman", Times, serif;
      }

      .sansserif {
	  font-family: Verdana, Arial, Helvetica, sans-serif;
      }

      .monospace {
	  font-family: "Lucida Console", Courier, monospace;
      }

    </style>

  </head>

  <body class="sansserif" link="red" vlink="maroon" alink="blue" background="white">
    <title>WSU Vancouver Mathematics and Statistics Seminar</title>


    <center>
      <table border="0" style="width:80%" valign="top">
	<tbody>
	  
	  <tr>
	    <td>
	      <p>
		<h1>WSU Vancouver Mathematics and
		    Statistics Seminar (Spring 2025)</h1>
	      </p>

	      <p>
		Welcome to the WSU Vancouver Seminar in Mathematics and Statistics!
		The Seminar meets on <font color=red><b>Wednesdays</b></font> at <font color=red><b>2:10&ndash;3:00 PM</b></font> in <font color=red><b>VUB 122</b></font> (unless mentioned otherwise).
		This is the Undergraduate Building (marked "N" in the <a  href="https://www.vancouver.wsu.edu/sites/www.vancouver.wsu.edu/files/wsuv_campusmap.pdf">campus map</a>).
		The seminar is open to the public, and here is some <a  href="https://www.vancouver.wsu.edu/campus-map-directions-and-parking-information">information for visitors</a>.
	      </p>
	      
	      <p>
		Students could sign up for <b>Math 592</b> (titled
		Seminar in Analysis) for 1 credit. Talks will be given
		by external speakers, as well as by WSUV faculty and
		students. Contact the organizer <a 
		href="index.html">Bala Krishnamoorthy</a> if you
		want to invite a speaker, or to give a talk.
	      </p>

	      <p>
		<a  href="Prev_VMathSeminar.html">Seminars
		from previous semesters</a>
	      </p>
	      <br>
	    </td>
	  </tr>
	</tbody>
      </table>
    </center>
    

    <center>
      <table id="t1">
	<thead>
	  <font size=+1>
	    <th width="7%">Date</th> <th width="23%">Speaker</th> <th width="38%">Topic</th> <!--<th width="7%">Slides</th>-->
	  </font>
	</thead>
	
	<tbody>

	  <tr>
	    <td> Jan &nbsp;8 </td>
	    <td colspan="2" align="left">
	      <a  href="https://jointmathematicsmeetings.org/jmm">No seminar</a>
	  </tr>
	  
	  <tr>
	    <td> Jan 15 </td>
	    <td align="left">
	      WSUV Math Grad Students
	    </td>

	    <td align="justify">
	      JMM Recap: Discussion
	      <div data-role="" class="">
		<div data-role="collapsible">
		  <h4>Abstract (click to read)</h4>
		  <p>
		    The Math grad students all attended the <a  href="https://jointmathematicsmeetings.org/jmm">Joint Mathematics Meetings</a> last week. We will have a discussion on what they learned from the conference, as well as their overall experience. We will also talk about the benefits of attending conferences for students.
		  </p>

		</div>
	      </div>
	    </td>
	  </tr>
	  
	  <tr>
	    <td> Jan 22 </td>
	    <td align="left">
	      Bala Krishnamoorthy
	    </td>

	    <td align="justify">
	      DeepCurrents: ML in Geometric Measure Theory
	      <div data-role="" class="">
		<div data-role="collapsible">
		  <h4>Abstract (click to read)</h4>
		  <p>
		    I will present a broad overview of area-minimizing
		    surface problems from Geometric Measure Theory
		    (GMT). Then I'll discuss the use of deep learning
		    frameworks in this context, using results mostly
		    from the paper on
		    <a 
		    href="https://arxiv.org/abs/2111.09383">DeepCurrents</a>. The
		    goal is to keep the discussion accessible to folks
		    (even without any background knowledge).
		  </p>

		</div>
	      </div>
	    </td>
	  </tr>

	  <tr>
	    <td> Jan 29 </td>
	    <td align="left">
	      <a 
	      href="https://elizabeththompson98.github.io/">Elizabeth
	      Thompson</a>, WSU
	    </td>

	    <td align="justify">
	      Using Persistent Homology for Classification 
	      <div data-role="" class="">
		<div data-role="collapsible">
		  <h4>Abstract (click to read)</h4>
		  <p>
		    We review the <A 
		    href="https://peerj.com/articles/cs-1195/">Persistent
		    Homology Classification Algorithm (PHCA)</a>, a
		    method that uses the lifetimes of topological
		    features in data to predict which classes of data
		    future points may belong to. PHCA, as opposed to
		    other PH classifiers, learns the topological
		    features of classes of data points rather than
		    those of each point individually. We share results
		    for which PHCA is compared to other binary and
		    multi-class classifiers, and is experimentally
		    shown to perform at or even better than some of
		    these current methods. We present these results on
		    diverse data sets, including iris plant, wheat
		    seeds, and social network ads data.
		  </p>

		</div>
	      </div>
	    </td>
	    
	  </tr>
	  

	  <tr>
	    <td> Feb 12 </td>
	    <td align="left">
	      <a 
	      href="https://sites.google.com/pdx.edu/jeffovall/">Jeff
	      Ovall</a>, PSU
	    </td>

	    <td align="justify">
	      Localization phenomena and Efficient Computation for the Magnetic Schrodinger Equation
	      <div data-role="" class="">
		<div data-role="collapsible">
		  <h4>Abstract (click to read)</h4>
		  <p>
		    The magnetic Schrodinger equation provides the
		    standard mathematical model for the motion of a
		    charged particle in a magnetic field.  The
		    solution of this equation, called the wave
		    function for the particle, provides (via its
		    modulus squared) the probability density of the
		    particle being located in a specific region at a
		    specific time.  As with many space-time partial
		    differential equations, significant insight can be
		    gleaned by considering the associated
		    time-independent eigenvalue problem, and this will
		    be the focus of our discussion.  More
		    specifically, we will first consider the
		    phenomenon of eigenvector localization, wherein
		    the "mass" of some eigenvectors is strongly
		    concentrated in relatively small portions of the
		    underlying spatial domain. The mechanisms driving
		    this localization are only partially understood,
		    and we will provide both theoretical and empirical
		    insight on the matter.  We will also demonstrate
		    that through a prudent choice of similarity
		    transform, which physicists would call a gauge
		    transform, we can significantly reduce the cost of
		    approximating eigenvalues and eigenvectors to a
		    prescribed level of accuracy.
		  </p>

		</div>
	      </div>
	    </td>
	    
	  </tr>


	  <tr>
	    <td> Feb 19 </td>
	    <td align=left>
	      <a  href="https://zachf3n.github.io/">Zach Fendler</a>, WSU
	    </td>
	    
	    <td align="justify">
	      Machine Learning in Optimization
	      <div data-role="" class="">
		<div data-role="collapsible">
		  <h4>Abstract (click to read)</h4>
		  <p>
		    Abstract: we will introduce Mixed Integer Programs
		    (MIPs), a class of optimization problems, and the
		    Branch-and-Bound (BNB) method to solve them. We
		    will then discuss machine learning (ML) techniques
		    used to learn effective branching strategies,
		    including an approach using a Tree Markov Decision
		    Process (tMDP). We will highlight key results from
		    the paper titled <a 
		    href="https://arxiv.org/abs/2205.11107">Learning
		    to branch with Tree MDPs</a>, focusing on how ML
		    techniques are applied in optimization to improve
		    branching decisions while addressing challenges
		    such as the credit assignment problem.
		  </p>
		</div>
	      </div>
	    </td>
	  </tr>

	  
	  <tr>
	    <td> <font color="red"><b>Feb 28</b></font> </td>
	    <td align="left" >
	      <a 
	      href="https://scholar.google.com/citations?hl=en&user=fEu_PHwAAAAJ">Safa
	      Mote</a>, PSU
	    </td>

	    <td align="justify">
	      Ensemble Oscillation Correction (EnOC): Leveraging
	      Oscillatory Modes to Improve Forecasts of Chaotic
	      Systems
	      <div data-role="" class="">
		<div data-role="collapsible">
		  <h4>Abstract (click to read)</h4>
		  <p>
		    Oscillatory modes of the climate system are among
		    its most predictable features, especially at
		    intraseasonal time scales. These oscillations can
		    be predicted well with data-driven methods, often
		    with better skill than dynamical models. However,
		    since the oscillations only represent a portion of
		    the total variance, a method for beneficially
		    combining oscillation forecasts with dynamical
		    forecasts of the full system was not previously
		    known. We introduce Ensemble Oscillation
		    Correction (EnOC), a general method to correct
		    oscillatory modes in ensemble forecasts from
		    dynamical models. We compute the ensemble
		    mean&mdash;or the ensemble probability
		    distribution&mdash;with only the best ensemble
		    members, as determined by their discrepancy from a
		    data-driven forecast of the oscillatory modes. We
		    also present an alternative method that uses
		    ensemble data assimilation to combine the
		    oscillation forecasts with an ensemble of
		    dynamical forecasts of the system (EnOC-DA). The
		    oscillatory modes are extracted with a time series
		    analysis method called multichannel singular
		    spectrum analysis (M-SSA), and forecast using an
		    analog method. We test these two methods using
		    chaotic toy models with significant oscillatory
		    components and show that they robustly reduce
		    error compared to the uncorrected ensemble. We
		    discuss the applications of this method to improve
		    prediction of monsoons as well as other parts of
		    the climate system. We also discuss possible
		    extensions of the method to other data-driven
		    forecasts, including machine learning.
		  </p>

		  <p>
		    Related reading:
		    <ol>
		      <li><a  href="https://doi.org/10.1175/jcli-d-20-0624.1">EnOC (2021)</a></li>
		      <li><a  href="https://doi.org/10.1073/pnas.2312573121">EnOC Monsoon (2024)</a></li>
		    </ol>
		  </p>

		</div>
	      </div>
	    </td>
	  </tr>


	  <tr>
	    <td> Mar &nbsp; 5 </td>
	    <td align=left>
	      <a  href="https://research.google/people/izhakshafran/">Izhak Shafran</a>, Google DeepMind
	    </td>
	    
	    <td align="justify">
	      (<b><font color=red>VECS 120</font></b>) Unpacking Large Language Models: Challenges, Costs, and Open Problems
	      <div data-role="" class="">
		<div data-role="collapsible">
		  <h4>Abstract (click to read)</h4>
		  <p>
		    In this talk, we'll explore the inner workings of
		    Large Language Models, diving into their two-phase
		    training process, the cost functions, and the
		    constraints that shape their optimization. After
		    this overview, we'll shift gears and take a look
		    at some of the open problems in the field,
		    including challenges with mixture-of-experts
		    models and the complexities of scaling model
		    sizes. It's a fascinating area with plenty of room
		    for growth and improvement, so come along for a
		    discussion on where things stand and where they
		    could go next!
		  </p>
		</div>
	      </div>
	    </td>
	  </tr>

	  <tr>
	    <td> Mar 19 </td>
	    <td align=left>
	      <a  href="https://labs.wsu.edu/climate/">Deepti Singh</a>, SoE, WSU
	    </td>
	    
	    <td align="justify">
	      The changing likelihood of heat extremes and their societal risks
	      <div data-role="" class="">
		<div data-role="collapsible">
		  <h4>Abstract (click to read)</h4>
		  <p>
		    Heat is the deadliest climate-related hazard in
		    the US. Several recent heatwaves have shattered
		    historical records and had catastrophic impacts on
		    human and natural communities. This talk will
		    focus on the drivers and impacts of extreme
		    heat. I will discuss research from my lab that
		    investigates the characteristics of extreme heat
		    on global to regional scales. I will also briefly
		    discuss how we quantify the role of human
		    activities in shaping individual heatwaves.
		  </p>
		</div>
	      </div>
	    </td>
	  </tr>

	  
	  <tr>
	    <td> Apr &nbsp; 2 </td>
	    <td align=left>
	      Anne-Marie Greggs, WSU
	    </td>
	    
	    <td align="justify">
	      Statistics of spiking neural networks based on counting processes
	      <div data-role="" class="">
		<div data-role="collapsible">
		  <h4>Abstract (click to read)</h4>
		  <p>
		    Estimating neuronal network activity as point
		    processes is challenging due to the singular
		    nature of events and high signal
		    dimensionality. This project analyzes spiking
		    neural networks (SNNs) using counting process
		    statistics, which are equivalent integral
		    representations of point processes. A small SNN of
		    Leaky Integrate-and-Fire (LIF) neurons is
		    simulated, and spiking events are counted as a
		    vector counting process \(N(t)\). The Poisson
		    counting process has known dynamic statistics over
		    time: both mean\((t)\) and variance\((t)\) are
		    proportional to time (\(= r_i(t)\) for each
		    independent source with rate \(r_i\)). By
		    standardizing the data, mean dynamics and
		    heteroscedasticity can be removed, allowing
		    comparison to a baseline Poisson counting process.
		  </p>
		</div>
	      </div>
	    </td>
	  </tr>


	  <tr>
	    <td> Apr 16 </td>
	    <td align=left>
	      <a href="https://liyapb.github.io/Liyabp.github.io/">Liya Boukhbinder</a>, WSU
	    </td>
	    
	    <td align="justify">
	      Homotopic deformations with minimal volume in higher dimensions
	      <div data-role="" class="">
		<div data-role="collapsible">
		  <h4>Abstract (click to read)</h4>
		  <p>
		    In this talk, we explore the problem of minimizing
		    volume in homotopic deformations between geometric
		    objects, beginning with low dimensions and
		    progressing toward more general settings.  We
		    start with a review of classical results for
		    homotopies between curves in \(\mathbb{R}^2\),
		    focusing on area-minimizing deformations. This
		    foundational understanding sets the stage for
		    extending these concepts to the convex case of
		    surfaces embedded in \(\mathbb{R}^3\) using the
		    geometric measure theory slices, where the notion
		    of minimal swept volume plays a central role. In
		    addition, we examine properties of more general
		    surfaces generated from two homotopic immersed
		    surfaces in \(\mathbb{R}^3\). We end with
		    directions for future work, particularly regarding
		    the existence and structure of minimal homotopies
		    in higher-dimensional spaces.
		  </p>
		</div>
	      </div>
	    </td>
	  </tr>


	</tbody>
      </table>
    </center>

    <hr>
    <address><a 
    href="mailto:kbala@wsu.edu"></a></address>
    <!-- hhmts start -->
    Last modified: Tue Apr 15 11:27:18 PDT 2025
    <!-- hhmts end -->

  </body>
</html>
